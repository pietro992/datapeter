
Loading the dataset

```{r}
net <- read.table("road-euroroad.edges", quote="\"", comment.char="")
```

I create a list of vertices
```{r}
vertices=sort(unique(unlist(net)))
vertices
```

I find the length of the vertices
```{r}
n=length(vertices)
n
```

Trovo il numero di link
```{r}
L=dim(net)[1]
L
```

I calculate the degree, i.e. the number of times a vector appears in the network
```{r}
Ki=table(unlist(net))
Ki=as.vector(unname(Ki))#usiamo unname per togliere associazione per avere un vettore
Ki
```

Soluzione(random integer; qui prendo sample casuale 1,2, n = ripetizione, replace = T), 1,2 sono le comunità di appartenenza di ogni nodo
```{r}
sol=sample(c(1,2),n,replace=T)
sol
```

I construct a surrogate matrix of the link matrix, each link is replaced by its community, then initialise linksCOM to the network
```{r}
linksCOM=net
```

I make a modification, in which I replace the columns with the ones that would be inserted by the communities. I use cbind which places columns of the same length side by side, to form an array. sol of linksCOM ,1 replaces each element in the first column of linksCOM its community in SOL. Then I do a cbind with second vector sol linksCOM ,2 identical applied on the second column of network(or linksCOM). I apply the square bracket because sol is a vector. The result will be a matrix with two columns in which instead of vertices are the communities to which they belong

```{r}
linksCOM=cbind(sol[linksCOM[,1]],sol[linksCOM[,2]])
linksCOM
```

I calculate modularity, so it equals empty set
```{r}
e=c()
```

At this point I calculate the number of links observed within each community with linksCOM. In linksCOM I take all the rows where we have 1 1, then all the elements of the first community when I go to see the number of links observed in the first and the elements of type 2 2 to calculate the number of links in community 2. Finally I do a for on two indexes, going to select a subnet with subsets. 

linksCOM first and second column elements = to i. When i = 1 I will take the rows with all elements done so, same for 2. Then I count with nrow the length of subi so that I get the quantity e[i] which will be the number of links in community 1. 

```{r}
for(i in 1:2){
  subi=subset(linksCOM,linksCOM[,1]==i & linksCOM[,2]==i) 
  e[i]=nrow(subi) 
}
```

Analysing the result of and , we have 298 links in community 1, and 402 links in community 2. 

```{r}
e

```

Now let us define the 'er' that is the normalisation of e with respect to the total number of links in the network

```{r}
er=e/L
er
```

Calculating ar and ar framework gave the number of i k es inside the communities. We start with empty vector

```{r}
a=c()
```

I am interested in looking at a subset of matrCOMK, i.e. a matrix in which I have the solution (understood as community) and next to it the degree. In the first column the community list for each node, in the second column the degree Ki. As a result we have, for each element, the community to which it belongs and the degree

```{r}
matrCOMK=cbind(sol,Ki)
matrCOMK
```
Now we proceed with the execution of a for loop but this time we are interested in the degree. a is defined as the average degree. In the for loop we calculate the total degree in each community with subset instruction, this time with matrCOM, and we must impose that the first column is == i (in this way I have selected all vertices, their degrees, which are in the community i esima). Inside the for loop I calculate the total of the second column of this subset matrix, i.e. the degree.

```{r}
for(i in 1:2){
  subi=subset(matrCOMK,matrCOMK[,1]==i)
  a[i]=sum(subi[,2]) 
}
```


a is standardised with ar; ar is obtained by dividing a by 2L, as the total sum of the degrees makes twice the number of links in the mtrice

```{r}
a 
ar=a/(2*L)
ar
ar2=ar^2
ar2
```

I am now ready to calculate the modularity which will be given by the sum of er - ar2

```{r}
modularity=sum(er-ar2)
modularity
```

Once the modularity has been calculated, it must be implemented within the for loop or other of the simulated annealing. But in r for variable definition problems, it is better to construct a function that calculates the modularity. I create a function which takes as input the list of links and a solution sol, and gives as output the modularity. modularity = funciton(I give as input two variables which I call net and solution) serves to have values to assign automatically. I use the two variables as we have used them so far and inside the curly brackets I copy what I have done so far, remembering that what net did remains net (which is the network), and sol becomes solution. Then I select and calculate from e=c() to modularity = sum(er-ar2) above, copy and paste it to follow, changing sol to solution.

```{r}
modularity = function(network=network, solution=solution){
  
  vertices=sort(unique(unlist(network)))
  n=length(vertices)
  L=dim(network)[1]
  L=nrow(network)
  Ki=table(unlist(network))
  Ki=as.vector(unname(Ki))
  
  linksCOM=network
  linksCOM=cbind(solution[linksCOM[,1]], solution[linksCOM[,2]])
  
  e=c()
  for(i in 1:2){
    subi=subset(linksCOM,linksCOM[,1]==i & linksCOM[,2]==i)
    e[i]=nrow(subi)
  }
  er=e/L
  matrCOMK=cbind(solution,Ki)
  
  a=c()
  for(i in 1:2){
    subi=subset(matrCOMK,matrCOMK[,1]==i)
    a[i]=sum(subi[, 2])
  }
  ar=a/(2*L)
  ar2=ar^2
  modularityAA=sum(er-ar2) #qui cambio modularity diversamente con modul. Ora do una quantità che consenta di riprenderci la modularità
  return(modularityAA) #quindi uso return(modularityAA) in modo che la funzione, preso in ingresso il network e la partizione, dia in uscita il valore di modularità. Compilo la funzione selezionando da modularity=function() a return(modul)
}
modularity(net, sol)
```

I have defined this modularity function, so now inside the simulated annealing routine I only need to call it up to calculate the modularity. By taking 200 random solutions, I saw the distances between them for the initial temperature setting.I create a vector modularityVEC and initialise it with empty vector

```{r}
modularityVEC = c()
```

Setto 200 simulazioni

```{r}
nsim = 200
```

I generate a for loop which iterates the procedure for determining solutions and subsequent modularity q up to nsim. I generate a random solution of elements 1,2 of length n with replace. I set an equality with modularity first defined. So I have modularity vector


```{r}
for(i in 1:nsim){
  sol=sample(c(1,2),n,replace=T) 
  modularityVEC[i] = modularity(net,sol) 
}
modularityVEC
```

Having made the modularities, I go to see the distances between all pairs of modularities, then create a dis initialised as a null quantity, and calculate all distances with two nested for loops. I do the differences between all distinct modularity pairs and use append to hang this distance on the vector of all dis distances, so I get the vector with all distances on which I can calculate the average. I then see the length dis after starting the for loop

```{r}
dis=c()
for(i in 1:(nsim-1)){
  for(j in (i+1):nsim){
    disttemp=abs(modularityVEC[i]- modularityVEC[j])
    dis=append(dis,disttemp)
  }
}
length(dis)
```

I calculate the average so that I can set the initial temperature 

```{r}
mm=mean(dis)
mm
```

Initialising temperatures

```{r}
T0=100*mm #T0 100 volte media distanze
Tf = mm/100
nsim = 10000 #simulazioni
```

I define the parameters of the exponential by which the temperature decreases
```{r}
A = T0
B = log(Tf/A)/nsim
A
B
```

Now I define the exponential for temperature, so I generate a vector and set all temperatures


```{r}
Temp=A*exp(B*(1:nsim))
length(Temp) #lunghezza dovrebbe essere 10000
min(Temp)
max(Temp)
```

Once I have written the definition of how the temperature must vary, and I have the phonation that calculates the modularity, I can start with the implementation of simulated annealing. I initialise a modularityPROC vector to remind me to take into account all the modularity values explored

```{r}
modularityPROC = c()
```

I initialise a solNEW to sol to get the first random initial solution

```{r}
solNEW = sol
```

Initialising optimal modularity

```{r}
modularityBEST=modularity(net, solNEW)
modularityBEST  #è negativa a quella iniziale
```

I initialise the for loop. In the SA I have to go and randomly choose a node and change its community. So I have to give a random sample from 1 to n, and go and change this to sol

```{r}
for(t in 1:nsim){
  nodeRAN=sample(1:n,1) #1 solo di lunghezza così ottengo un numero naturale tra 1 n che mi indica il nodo
  solNEW[nodeRAN]=ifelse(sol[nodeRAN]==1, 2, 1) #così abbiamo definito la variazione elementare della soluzione. facciamo update della modularità, quind confrontiamo con modularità best, quella inizializzata al valore semplice
  modularityNEW=modularity(net, solNEW)
  if(modularityNEW >= modularityBEST){
    sol=solNEW
    modularityBEST=modularityNEW
  }else{
    diff=modularityBEST-modularityNEW
    p=exp(-diff/Temp[t]) #probabilità
    ran=runif(1) #devo generare un numero casuale tra 0 e 1
    if(ran<=p){ # transizione a nuova soluzione
      sol=solNEW
      modularityBEST=modularityNEW
    }
  }
  modularityPROC[t]=modularityBEST #registro valore della modularità
}
```

Realising the plot

```{r}
plot(modularityPROC, type = "l")
#è salita e il vettore è arrivato a 0.04
modularityBEST

```

Network graphic design with Cytoscape
```{r}
library(igraph)
library(RCy3)
net1 <- read_graph("road-euroroad.edges")
cytoscapePing ()
cytoscapeVersionInfo ()

createNetworkFromIgraph(net1, title = "From Igraph", collection = "My Igraph Network Collection")
```

Graph interpretation:
From the network graph we can see that there are more cohesive communities, highlighting roads perhaps belonging to certain European regions, and detached networks that might suggest regions not connected by the same roads.


